{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import easygdf\n",
    "import mne\n",
    "import json\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, MaxPooling1D, Dropout, Flatten\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import get_data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def squeeze_excitation_block(inputs, r):\n",
    "    filters = inputs.shape[-1]\n",
    "    se = layers.GlobalAveragePooling1D()(inputs)\n",
    "    se = layers.Dense(filters // r, activation='relu')(se)\n",
    "    se = layers.Dense(filters, activation='sigmoid')(se)\n",
    "    se = layers.Reshape((1, filters))(se)\n",
    "    return layers.multiply([inputs, se])\n",
    "\n",
    "input_shape = (1000, 22)\n",
    "\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# First Layer\n",
    "x = layers.Conv1D(32, 20, strides=2, padding='same', kernel_regularizer=l2(0.01))(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "x = squeeze_excitation_block(x, r=8)\n",
    "x = layers.MaxPooling1D()(x)\n",
    "\n",
    "# Second Layer\n",
    "x = layers.Conv1D(32, 9, strides=2, padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "x = squeeze_excitation_block(x, r=8)\n",
    "layer1_output = layers.MaxPooling1D()(x)\n",
    "\n",
    "# Third Layer\n",
    "x = layers.Conv1D(32, 5, strides=1, padding='same', kernel_regularizer=l2(0.01))(layer1_output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "\n",
    "\n",
    "# Fourth Layer\n",
    "x = layers.Conv1D(32, 5, strides=1, padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "x = squeeze_excitation_block(x, r=8)\n",
    "x = layers.Add()([x, layer1_output])\n",
    "layer4_output = layers.MaxPooling1D()(x)\n",
    "\n",
    "# Fifth Layer\n",
    "x = layers.Conv1D(32, 3, strides=1, padding='same', kernel_regularizer=l2(0.01))(layer4_output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "\n",
    "\n",
    "# Sixth Layer\n",
    "x = layers.Conv1D(32, 3, strides=1, padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "x = squeeze_excitation_block(x, r=8)\n",
    "x = layers.Add()([x, layer4_output])\n",
    "x = layers.MaxPooling1D()(x)\n",
    "\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excitation_block(inputs, r):\n",
    "    filters = inputs.shape[-1]\n",
    "    se = layers.GlobalAveragePooling1D()(inputs)\n",
    "    se = layers.Dense(filters // r, activation='relu')(se)\n",
    "    se = layers.Dense(filters, activation='sigmoid')(se)\n",
    "    se = layers.Reshape((1, filters))(se)\n",
    "    return layers.multiply([inputs, se])\n",
    "\n",
    "input_shape = (1000, 22)\n",
    "\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# First Layer\n",
    "x = layers.Conv1D(32, 13, strides=2, padding='same', kernel_regularizer=l2(0.01))(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "x = squeeze_excitation_block(x, r=8)\n",
    "\n",
    "# Second Layer\n",
    "x = layers.Conv1D(32, 7, strides=2, padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "x = squeeze_excitation_block(x, r=8)\n",
    "x = layers.MaxPooling1D()(x)\n",
    "\n",
    "# Third Layer\n",
    "x = layers.Conv1D(32, 5, strides=1, padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "x = squeeze_excitation_block(x, r=8)\n",
    "layer3_output = layers.MaxPooling1D()(x)\n",
    "\n",
    "# Fourth Layer\n",
    "x = layers.Conv1D(32, 3, strides=1, padding='same', kernel_regularizer=l2(0.01))(layer3_output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "\n",
    "# Fifth Layer\n",
    "x = layers.Conv1D(32, 3, strides=1, padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "x = squeeze_excitation_block(x, r=8)\n",
    "x = layers.Add()([x, layer3_output])\n",
    "x = layers.MaxPooling1D()(x)\n",
    "\n",
    "# Dropout layer\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Flatten layer\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create model\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third branch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excitation_block(inputs, r):\n",
    "    filters = inputs.shape[-1]\n",
    "    se = layers.GlobalAveragePooling1D()(inputs)\n",
    "    se = layers.Dense(filters // r, activation='relu')(se)\n",
    "    se = layers.Dense(filters, activation='sigmoid')(se)\n",
    "    se = layers.Reshape((1, filters))(se)\n",
    "    return layers.multiply([inputs, se])\n",
    "\n",
    "input_shape = (1000, 22)\n",
    "\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# First Layer\n",
    "x = layers.Conv1D(32, 15, strides=2, padding='same', kernel_regularizer=l2(0.01))(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "x = squeeze_excitation_block(x, r=8)\n",
    "x = layers.MaxPooling1D()(x)\n",
    "\n",
    "# Second Layer\n",
    "x = layers.Conv1D(32, 10, strides=2, padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "x = squeeze_excitation_block(x, r=8)\n",
    "\n",
    "# Third Layer\n",
    "x = layers.Conv1D(32, 5, strides=1, padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "x = squeeze_excitation_block(x, r=8)\n",
    "x = layers.MaxPooling1D()(x)\n",
    "\n",
    "# Fourth Layer\n",
    "x = layers.Conv1D(48, 3, strides=1, padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ELU()(x)\n",
    "x = squeeze_excitation_block(x, r=8)\n",
    "x = layers.MaxPooling1D()(x)\n",
    "\n",
    "# Dropout layer\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Flatten layer\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create model\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the final version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 22, 1)]              0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 11, 32)               672       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 11, 32)               128       ['conv1d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 22, 1)]              0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 22, 1)]              0         []                            \n",
      "                                                                                                  \n",
      " elu (ELU)                   (None, 11, 32)               0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 11, 32)               448       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 11, 32)               512       ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 32)                   0         ['elu[0][0]']                 \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 11, 32)               128       ['conv1d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 11, 32)               128       ['conv1d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 4)                    132       ['global_average_pooling1d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " elu_3 (ELU)                 (None, 11, 32)               0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " elu_6 (ELU)                 (None, 11, 32)               0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   160       ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2  (None, 32)                   0         ['elu_3[0][0]']               \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4  (None, 32)                   0         ['elu_6[0][0]']               \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1, 32)                0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 4)                    132       ['global_average_pooling1d_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 4)                    132       ['global_average_pooling1d_4[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " multiply (Multiply)         (None, 11, 32)               0         ['elu[0][0]',                 \n",
      "                                                                     'reshape[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 32)                   160       ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 32)                   160       ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1  (None, 5, 32)                0         ['multiply[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)         (None, 1, 32)                0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)         (None, 1, 32)                0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 3, 32)                9248      ['max_pooling1d[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)       (None, 11, 32)               0         ['elu_3[0][0]',               \n",
      "                                                                     'reshape_2[0][0]']           \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)       (None, 11, 32)               0         ['elu_6[0][0]',               \n",
      "                                                                     'reshape_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 3, 32)                128       ['conv1d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 6, 32)                7200      ['multiply_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 6, 32)                10272     ['multiply_4[0][0]']          \n",
      "                                                                                                  \n",
      " elu_1 (ELU)                 (None, 3, 32)                0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 6, 32)                128       ['conv1d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 6, 32)                128       ['conv1d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 32)                   0         ['elu_1[0][0]']               \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " elu_4 (ELU)                 (None, 6, 32)                0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " elu_7 (ELU)                 (None, 6, 32)                0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 4)                    132       ['global_average_pooling1d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3  (None, 32)                   0         ['elu_4[0][0]']               \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " global_average_pooling1d_5  (None, 32)                   0         ['elu_7[0][0]']               \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 32)                   160       ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 4)                    132       ['global_average_pooling1d_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 4)                    132       ['global_average_pooling1d_5[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 1, 32)                0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 32)                   160       ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 32)                   160       ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)       (None, 3, 32)                0         ['elu_1[0][0]',               \n",
      "                                                                     'reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)         (None, 1, 32)                0         ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)         (None, 1, 32)                0         ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPoolin  (None, 1, 32)                0         ['multiply_1[0][0]']          \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)       (None, 6, 32)                0         ['elu_4[0][0]',               \n",
      "                                                                     'reshape_3[0][0]']           \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)       (None, 6, 32)                0         ['elu_7[0][0]',               \n",
      "                                                                     'reshape_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 1, 32)                5152      ['max_pooling1d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 6, 32)                5152      ['multiply_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 6, 32)                5152      ['multiply_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 1, 32)                128       ['conv1d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 6, 32)                128       ['conv1d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 6, 32)                128       ['conv1d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " elu_2 (ELU)                 (None, 1, 32)                0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " elu_5 (ELU)                 (None, 6, 32)                0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " elu_8 (ELU)                 (None, 6, 32)                0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 32)                   0         ['elu_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 192)                  0         ['elu_5[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 192)                  0         ['elu_8[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 416)                  0         ['flatten[0][0]',             \n",
      "                                                                     'flatten_1[0][0]',           \n",
      "                                                                     'flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 416)                  0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 4)                    1668      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 48380 (188.98 KB)\n",
      "Trainable params: 47804 (186.73 KB)\n",
      "Non-trainable params: 576 (2.25 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the squeeze excitation block function\n",
    "def squeeze_excitation_block(inputs, r):\n",
    "    filters = inputs.shape[-1]\n",
    "    se = layers.GlobalAveragePooling1D()(inputs)\n",
    "    se = layers.Dense(filters // r, activation='relu')(se)\n",
    "    se = layers.Dense(filters, activation='sigmoid')(se)\n",
    "    se = layers.Reshape((1, filters))(se)\n",
    "    return layers.multiply([inputs, se])\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define input shape\n",
    "input_shape = (22,1)\n",
    "\n",
    "# Define input layers for each branch\n",
    "input_1 = tf.keras.Input(shape=input_shape)\n",
    "input_2 = tf.keras.Input(shape=input_shape)\n",
    "input_3 = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# First Branch\n",
    "x1 = layers.Conv1D(32, 20, strides=2, padding='same', kernel_regularizer=l2(0.01))(input_1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.ELU()(x1)\n",
    "x1 = squeeze_excitation_block(x1, r=8)\n",
    "x1 = layers.MaxPooling1D()(x1)\n",
    "\n",
    "x1 = layers.Conv1D(32, 9, strides=2, padding='same', kernel_regularizer=l2(0.01))(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.ELU()(x1)\n",
    "x1 = squeeze_excitation_block(x1, r=8)\n",
    "x1 = layers.MaxPooling1D()(x1)\n",
    "\n",
    "x1 = layers.Conv1D(32, 5, strides=1, padding='same', kernel_regularizer=l2(0.01))(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.ELU()(x1)\n",
    "\n",
    "x1 = layers.Flatten()(x1)\n",
    "\n",
    "# Second Branch\n",
    "x2 = layers.Conv1D(32, 13, strides=2, padding='same', kernel_regularizer=l2(0.01))(input_2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.ELU()(x2)\n",
    "x2 = squeeze_excitation_block(x2, r=8)\n",
    "\n",
    "x2 = layers.Conv1D(32, 7, strides=2, padding='same', kernel_regularizer=l2(0.01))(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.ELU()(x2)\n",
    "x2 = squeeze_excitation_block(x2, r=8)\n",
    "\n",
    "x2 = layers.Conv1D(32, 5, strides=1, padding='same', kernel_regularizer=l2(0.01))(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.ELU()(x2)\n",
    "\n",
    "x2 = layers.Flatten()(x2)\n",
    "\n",
    "# Third Branch\n",
    "x3 = layers.Conv1D(32, 15, strides=2, padding='same', kernel_regularizer=l2(0.01))(input_3)\n",
    "x3 = layers.BatchNormalization()(x3)\n",
    "x3 = layers.ELU()(x3)\n",
    "x3 = squeeze_excitation_block(x3, r=8)\n",
    "\n",
    "x3 = layers.Conv1D(32, 10, strides=2, padding='same', kernel_regularizer=l2(0.01))(x3)\n",
    "x3 = layers.BatchNormalization()(x3)\n",
    "x3 = layers.ELU()(x3)\n",
    "x3 = squeeze_excitation_block(x3, r=8)\n",
    "\n",
    "x3 = layers.Conv1D(32, 5, strides=1, padding='same', kernel_regularizer=l2(0.01))(x3)\n",
    "x3 = layers.BatchNormalization()(x3)\n",
    "x3 = layers.ELU()(x3)\n",
    "\n",
    "x3 = layers.Flatten()(x3)\n",
    "\n",
    "# Concatenate the outputs of three branches\n",
    "merged = layers.concatenate([x1, x2, x3])\n",
    "\n",
    "# Dropout layer\n",
    "x = layers.Dropout(0.5)(merged)\n",
    "\n",
    "# # Flatten layer\n",
    "# x = layers.Flatten()(x)\n",
    "\n",
    "# # Dense layer\n",
    "# x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "# Output layer\n",
    "output = layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[input_1, input_2, input_3], outputs=output)\n",
    "\n",
    "# Compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A01E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A02E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n",
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A03E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n",
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n",
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A04T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '32766', '768', '769', '770', '771', '772']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A04E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A05T.gdf...\n",
      "GDF file detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n",
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A05E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n",
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A06T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A06E.gdf...\n",
      "GDF file detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A07E.gdf...\n",
      "GDF file detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n",
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A08T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A08E.gdf...\n",
      "GDF file detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n",
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A09T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Extracting EDF parameters from d:\\porojects\\EEG classification\\datasets\\BCICIV_2a_gdf\\A09E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n",
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n",
      "C:\\Users\\nima8\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:120: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    }
   ],
   "source": [
    "events_with_labels_arrays=get_data.event_position()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arrays=get_data.save_data_in_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = [\"A01T\", \"A02T\", \"A03T\",\"A04T\",\"A05T\",\"A06T\",\"A07T\",\"A08T\",\"A09T\"]\n",
    "\n",
    "X_train=[]\n",
    "\n",
    "for label in labels:\n",
    "\n",
    "    temp_data=data_arrays[label]\n",
    "    temp_events=events_with_labels_arrays[label]\n",
    "    for i in range(len(temp_events)):\n",
    "    \n",
    "        if temp_events[i,1]==769 or temp_events[i,1]==770 or temp_events[i,1]==771 or temp_events[i,1]==772 :\n",
    "\n",
    "            ev=temp_events[i,1]\n",
    "            position=temp_events[i,0]\n",
    "            for j in range(position, position+1000):\n",
    "\n",
    "                temp=np.append(temp_data[j,1:23],ev)\n",
    "                X_train.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "#Separate features (X) and labels (y)\n",
    "X = X_train[:, :-1]  # Extract all rows and all columns except the last one\n",
    "Y = X_train[:, -1]   # Extract all rows and only the last column\n",
    "\n",
    "Y = Y.reshape(-1, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y)):\n",
    "    if Y[i]==769:\n",
    "        Y[i]=0\n",
    "    elif Y[i]==770:\n",
    "        Y[i]=1\n",
    "    elif Y[i]==771:\n",
    "        Y[i]=2    \n",
    "    elif Y[i]==772:\n",
    "        Y[i]=3    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_, y_train, y_ =train_test_split(X, Y, test_size=0.20, random_state=1)\n",
    "\n",
    "# x_cv, x_test, y_cv, y_test =train_test_split(x_, y_, test_size=0.50, random_state=1)\n",
    "\n",
    "# del x_ ,y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate shuffled indices\n",
    "indices = np.arange(len(x_train))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Shuffle x_train and y_train using the shuffled indices\n",
    "x_train_shuffled = x_train[indices]\n",
    "y_train_shuffled = y_train[indices]\n",
    "\n",
    "# Now x_train_shuffled and y_train_shuffled are shuffled while maintaining correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "25920/25920 [==============================] - 228s 8ms/step - loss: 1.4410 - accuracy: 0.2653 - val_loss: 1.3838 - val_accuracy: 0.2754\n",
      "Epoch 2/400\n",
      "10376/25920 [===========>..................] - ETA: 2:01 - loss: 1.3839 - accuracy: 0.2746"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit([x_train_shuffled, x_train_shuffled, x_train_shuffled], y_train_shuffled, epochs\u001b[39m=\u001b[39;49m\u001b[39m400\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Plot the training loss\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining Loss\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\OCR\\okernel\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\OCR\\okernel\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\OCR\\okernel\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\OCR\\okernel\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\OCR\\okernel\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\OCR\\okernel\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\OCR\\okernel\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\OCR\\okernel\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32md:\\OCR\\okernel\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32md:\\OCR\\okernel\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history=model.fit([x_train_shuffled, x_train_shuffled, x_train_shuffled], y_train_shuffled, epochs=400, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "okernel",
   "language": "python",
   "name": "okernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
